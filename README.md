# AWS Bedrock Chatbot Service

A simple, production-ready chatbot service built with FastAPI and AWS Bedrock, featuring Claude AI models.

## Features

- RESTful API built with FastAPI
- AWS Bedrock integration with Claude models
- Conversation history support
- Docker containerization
- Comprehensive logging
- Environment-based configuration
- Health check endpoints

## Project Structure

```
moch-qna-bot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py          # API endpoints
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ bedrock_service.py # Bedrock integration
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ logger.py          # Logging configuration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py                # FastAPI application
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py            # Configuration settings
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API.md                 # API documentation
â”‚   â”œâ”€â”€ DEPLOYMENT.md          # Deployment guide
â”‚   â”œâ”€â”€ SYSTEM_PROMPTS.md      # System prompts guide
â”‚   â””â”€â”€ KNOWLEDGE_BASE.md      # Knowledge base integration guide
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ system_prompt.txt      # Your custom system prompt
â”‚   â”œâ”€â”€ system_prompt.example.txt  # Example template
â”‚   â”œâ”€â”€ knowledge_base.json    # Your data (auto-injected into prompt)
â”‚   â””â”€â”€ knowledge_base.example.json  # Example structure
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html             # Chat UI
â”‚   â”œâ”€â”€ style.css              # Styles
â”‚   â””â”€â”€ app.js                 # Frontend logic
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_api.py            # API tests
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## Prerequisites

- Python 3.11+
- AWS account with Bedrock access
- AWS credentials configured
- Docker (optional, for containerized deployment)

## Quick Start

### 1. Clone and Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
# Copy example environment file
cp .env.example .env

# Edit .env with your AWS credentials
```

### 3. Setup System Prompt and Knowledge Base

```bash
# Copy example system prompt
cp prompts/system_prompt.example.txt prompts/system_prompt.txt

# Copy example knowledge base
cp prompts/knowledge_base.example.json prompts/knowledge_base.json

# Edit with your custom prompt and data
nano prompts/system_prompt.txt
nano prompts/knowledge_base.json
```

The knowledge base JSON will be automatically injected into the `<knowledge_base>` section of your system prompt. See [Knowledge Base Guide](docs/KNOWLEDGE_BASE.md) for details.

### 4. Run the Service

**Option A: Direct Python**
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**Option B: Docker Compose**
```bash
docker-compose up --build
```

### 5. Access the Application

**Web UI (Recommended):**
- ğŸŒ Chat Interface: http://localhost:8000

**API & Documentation:**
- ğŸ“š API Documentation: http://localhost:8000/docs
- ğŸ’š Health Check: http://localhost:8000/health
- ğŸ”Œ Chat Endpoint: http://localhost:8000/api/v1/chat

## Usage

### Web Interface

Open your browser and go to **http://localhost:8000** to access the chat interface.

**Features:**
- âœ… Hebrew (RTL) support
- âœ… Conversation history (persists in browser)
- âœ… Beautiful, responsive design
- âœ… Real-time typing indicators
- âœ… Clickable links in responses
- âœ… Clear conversation button
- âœ… Mobile-friendly

### API Usage

### Basic Chat Request

```bash
curl -X POST "http://localhost:8000/api/v1/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Hello, how are you?",
    "temperature": 0.7,
    "max_tokens": 2048
  }'
```

### With Conversation History

```bash
curl -X POST "http://localhost:8000/api/v1/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What did we discuss earlier?",
    "conversation_history": [
      {"role": "user", "content": "Tell me about AWS Bedrock"},
      {"role": "assistant", "content": "AWS Bedrock is..."}
    ]
  }'
```

### List Available Models

```bash
curl "http://localhost:8000/api/v1/models"
```

## Configuration

Configure the service through environment variables or `.env` file:

| Variable | Description | Default |
|----------|-------------|---------|
| `AWS_REGION` | AWS region | `us-east-1` |
| `AWS_ACCESS_KEY_ID` | AWS access key | - |
| `AWS_SECRET_ACCESS_KEY` | AWS secret key | - |
| `DEFAULT_MODEL_ID` | Default Bedrock model | `anthropic.claude-3-sonnet-20240229-v1:0` |
| `DEFAULT_TEMPERATURE` | Default temperature | `0.7` |
| `DEFAULT_MAX_TOKENS` | Default max tokens | `2048` |
| `SYSTEM_PROMPT_FILE` | Path to system prompt file | `prompts/system_prompt.txt` |
| `KNOWLEDGE_BASE_FILE` | Path to knowledge base JSON | `prompts/knowledge_base.json` |
| `HOST` | Server host | `0.0.0.0` |
| `PORT` | Server port | `8000` |
| `LOG_LEVEL` | Logging level | `INFO` |

## Available Models

- `anthropic.claude-3-sonnet-20240229-v1:0` (Default)
- `anthropic.claude-3-haiku-20240307-v1:0`
- `anthropic.claude-3-opus-20240229-v1:0`
- `anthropic.claude-v2:1`
- `anthropic.claude-v2`

## Testing

```bash
# Install test dependencies
pip install pytest pytest-asyncio httpx

# Run tests
pytest tests/
```

## Documentation

- [API Documentation](docs/API.md) - Complete API reference
- [Deployment Guide](docs/DEPLOYMENT.md) - Deploy to AWS and other platforms
- [System Prompts Guide](docs/SYSTEM_PROMPTS.md) - Customize the AI assistant's behavior
- [Knowledge Base Guide](docs/KNOWLEDGE_BASE.md) - Integrate JSON data into your prompts

## License

MIT

## Support

For issues and questions, please open an issue on GitHub.
